{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##########################################\n",
    "# 1) LOADING + SCALING + GROUPING\n",
    "##########################################\n",
    "\n",
    "def load_data():\n",
    "    train = pd.read_csv(\"playground-series-s5e1/train.csv\")\n",
    "    test  = pd.read_csv(\"playground-series-s5e1/test.csv\")\n",
    "    sub   = pd.read_csv(\"playground-series-s5e1/sample_submission.csv\")\n",
    "    return train, test, sub\n",
    "\n",
    "def fill_missing_mean(df):\n",
    "    \"\"\"Fill missing in 'num_sold' with mean (only for train).\"\"\"\n",
    "    df['num_sold'] = df['num_sold'].fillna(df['num_sold'].mean())\n",
    "    return df\n",
    "\n",
    "def kaggle_transform_num_sold(df):\n",
    "    \"\"\"\n",
    "    Applies min–max -> log1p -> sqrt -> IQR clip to `num_sold`.\n",
    "    Returns (df, transform_stats) so we can invert it later.\n",
    "    \"\"\"\n",
    "    num_sold_min = df['num_sold'].min()\n",
    "    num_sold_max = df['num_sold'].max()\n",
    "\n",
    "    # 1) min–max\n",
    "    df['num_sold'] = (df['num_sold'] - num_sold_min) / (num_sold_max - num_sold_min)\n",
    "\n",
    "    # 2) log1p\n",
    "    df['num_sold'] = np.log1p(df['num_sold'])\n",
    "\n",
    "    # 3) sqrt\n",
    "    df['num_sold'] = np.sqrt(df['num_sold'])\n",
    "\n",
    "    # 4) IQR clip\n",
    "    q1 = df['num_sold'].quantile(0.25)\n",
    "    q3 = df['num_sold'].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    df['num_sold'] = df['num_sold'].clip(lower, upper)\n",
    "\n",
    "    transform_stats = {\n",
    "        'num_sold_min': num_sold_min,\n",
    "        'num_sold_max': num_sold_max,\n",
    "        'lower_bound': lower,\n",
    "        'upper_bound': upper\n",
    "    }\n",
    "    return df, transform_stats\n",
    "\n",
    "def invert_kaggle_transform(y_pred_transformed, stats):\n",
    "    \"\"\"\n",
    "    Invert the transform: square -> expm1 -> invert min–max.\n",
    "    \"\"\"\n",
    "    # 1) square\n",
    "    y_pred = y_pred_transformed**2\n",
    "    # 2) expm1\n",
    "    y_pred = np.expm1(y_pred)\n",
    "    # 3) min–max invert\n",
    "    num_sold_min = stats['num_sold_min']\n",
    "    num_sold_max = stats['num_sold_max']\n",
    "    y_pred = y_pred * (num_sold_max - num_sold_min) + num_sold_min\n",
    "    return y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##########################################\n",
    "# 2) BUILD SLIDING WINDOWS BY GROUP\n",
    "##########################################\n",
    "def build_group_windows(group_df, seq_len=96, pred_len=1):\n",
    "    \"\"\"\n",
    "    group_df: columns [date, country, store, product, num_sold, ...]\n",
    "    We'll assume only 'num_sold' is used for the time-series input.\n",
    "    Return lists of x_seq, y_seq for each sliding window in this group.\n",
    "    Single-step approach: x_seq => last 96 days, y_seq => next day.\n",
    "    \"\"\"\n",
    "    group_df = group_df.sort_values('date')  # sort by date\n",
    "    arr = group_df['num_sold'].values  # shape (N,)\n",
    "\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    # We'll also store the corresponding date of the label so we can track it if needed\n",
    "    # but for pure training, it's not mandatory. We'll omit for brevity.\n",
    "\n",
    "    N = len(arr)\n",
    "    for i in range(N - seq_len - pred_len + 1):\n",
    "        x_seq = arr[i : i+seq_len]                 # last 96\n",
    "        y_seq = arr[i+seq_len : i+seq_len+pred_len]# next day\n",
    "        x_list.append(x_seq)\n",
    "        y_list.append(y_seq[0])  # single-step => just 1 value\n",
    "\n",
    "    return x_list, y_list\n",
    "\n",
    "class MultiSeriesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Collects sliding windows from all (country, store, product) groups.\n",
    "    \"\"\"\n",
    "    def __init__(self, train_df, seq_len=96):\n",
    "        self.seq_len = seq_len\n",
    "        # group by (country, store, product)\n",
    "        self.samples = []\n",
    "        gdf = train_df.groupby(['country','store','product'], as_index=False)\n",
    "\n",
    "        for (coun,st,prod), subdf in gdf:\n",
    "            x_list, y_list = build_group_windows(subdf, seq_len=seq_len, pred_len=1)\n",
    "            for x_seq, y_val in zip(x_list, y_list):\n",
    "                self.samples.append((x_seq, y_val))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_seq, y_val = self.samples[idx]\n",
    "        x_seq = torch.tensor(x_seq, dtype=torch.float32)  # shape [seq_len]\n",
    "        y_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "        return x_seq, y_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##########################################\n",
    "# 3) FAN MODEL\n",
    "##########################################\n",
    "# We'll do a minimal approach: input is [B, seq_len], we pretend that's [B, seq_len, 1].\n",
    "# Then we do the same FAN-based Transformer approach over time steps.\n",
    "from layers.SelfAttention_Family import FullAttention, AttentionLayer\n",
    "from layers.Transformer_EncDec import Decoder, DecoderLayer, Encoder, EncoderLayer\n",
    "from layers.Embed import DataEmbedding\n",
    "from layers.FANLayer import FANLayer\n",
    "\n",
    "class FANTimeSeries(nn.Module):\n",
    "    \"\"\"\n",
    "    A multi-step Transformer for a single time-series input dimension (or we do enc_in=1).\n",
    "    We interpret x: [B, seq_len] -> [B, seq_len, 1].\n",
    "    \"\"\"\n",
    "    def __init__(self, seq_len=96, d_model=128, e_layers=3, d_layers=1):\n",
    "        super().__init__()\n",
    "        class Configs:\n",
    "            enc_in = 1\n",
    "            dec_in = 1\n",
    "            c_out = 1\n",
    "            d_model = 128\n",
    "            embed = 'timeF'\n",
    "            freq = 'h'\n",
    "            dropout = 0.1\n",
    "            e_layers = 3\n",
    "            d_layers = 1\n",
    "            d_ff = 512\n",
    "            n_heads = 8\n",
    "            factor = 5\n",
    "            activation = 'gelu'\n",
    "            output_attention = False\n",
    "            pred_len = 1\n",
    "            exp_setting = 0\n",
    "        configs = Configs()\n",
    "\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.enc_embedding = DataEmbedding(1, configs.d_model, configs.embed, configs.freq, configs.dropout)\n",
    "        self.dec_embedding = DataEmbedding(1, configs.d_model, configs.embed, configs.freq, configs.dropout)\n",
    "        self.fan_layer = FANLayer(configs.d_model, configs.d_model)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(False, configs.factor,\n",
    "                                      attention_dropout=configs.dropout,\n",
    "                                      output_attention=configs.output_attention),\n",
    "                        configs.d_model,\n",
    "                        configs.n_heads),\n",
    "                    configs.d_model,\n",
    "                    configs.d_ff,\n",
    "                    dropout=configs.dropout,\n",
    "                    activation=configs.activation,\n",
    "                    exp_setting=configs.exp_setting\n",
    "                )\n",
    "                for _ in range(configs.e_layers)\n",
    "            ],\n",
    "            norm_layer=nn.LayerNorm(configs.d_model),\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(True, configs.factor, attention_dropout=configs.dropout, output_attention=False),\n",
    "                        configs.d_model,\n",
    "                        configs.n_heads,\n",
    "                    ),\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(False, configs.factor, attention_dropout=configs.dropout, output_attention=False),\n",
    "                        configs.d_model,\n",
    "                        configs.n_heads,\n",
    "                    ),\n",
    "                    configs.d_model,\n",
    "                    configs.d_ff,\n",
    "                    dropout=configs.dropout,\n",
    "                    activation=configs.activation,\n",
    "                    exp_setting=configs.exp_setting,\n",
    "                )\n",
    "                for _ in range(configs.d_layers)\n",
    "            ],\n",
    "            norm_layer=nn.LayerNorm(configs.d_model),\n",
    "            projection=nn.Linear(configs.d_model, 1, bias=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: shape [B, seq_len], single feature -> interpret as [B, seq_len, 1].\n",
    "        We'll do a single-step decode => x_dec shape also [B, 1, 1].\n",
    "        \"\"\"\n",
    "        device = x.device\n",
    "        B, L = x.shape\n",
    "        x_enc = x.unsqueeze(-1)  # [B, L, 1]\n",
    "        # We'll create a single \"start token\" or zero for the decoder\n",
    "        x_dec = torch.zeros([B, 1, 1], device=device)\n",
    "\n",
    "        # dummy time features\n",
    "        x_mark_enc = torch.zeros([B, L, 4], device=device)\n",
    "        x_mark_dec = torch.zeros([B, 1, 4], device=device)\n",
    "\n",
    "        enc_out = self.enc_embedding(x_enc, x_mark_enc)  # [B,L,d_model]\n",
    "        enc_out = self.fan_layer(enc_out)\n",
    "        enc_out, _ = self.encoder(enc_out)\n",
    "\n",
    "        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n",
    "        dec_out = self.decoder(dec_out, enc_out)  # shape [B,1,1]\n",
    "        # => single-step forecast\n",
    "        return dec_out.squeeze(1).squeeze(-1)  # [B]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated Memory: 8.22 MB\n",
      "Cached Memory: 24.00 MB\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 108\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubmission.csv created!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 108\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 46\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(pred, y_val)\n\u001b[1;32m     45\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 46\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(x_seq)\n\u001b[1;32m     48\u001b[0m total_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_ds)\n",
      "File \u001b[0;32m~/Python/FAN-MicroDoppler/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/Python/FAN-MicroDoppler/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/Python/FAN-MicroDoppler/.venv/lib/python3.12/site-packages/torch/optim/adam.py:223\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    211\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    213\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    214\u001b[0m         group,\n\u001b[1;32m    215\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    220\u001b[0m         state_steps,\n\u001b[1;32m    221\u001b[0m     )\n\u001b[0;32m--> 223\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Python/FAN-MicroDoppler/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Python/FAN-MicroDoppler/.venv/lib/python3.12/site-packages/torch/optim/adam.py:784\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    782\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 784\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Python/FAN-MicroDoppler/.venv/lib/python3.12/site-packages/torch/optim/adam.py:483\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m grad_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m found_inf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m differentiable, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_foreach ops don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support autograd\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 483\u001b[0m grouped_tensors \u001b[38;5;241m=\u001b[39m \u001b[43mOptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_group_tensors_by_device_and_dtype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[list-item]\u001b[39;49;00m\n\u001b[1;32m    485\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (\n\u001b[1;32m    487\u001b[0m     device_params_,\n\u001b[1;32m    488\u001b[0m     device_grads_,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    492\u001b[0m     device_state_steps_,\n\u001b[1;32m    493\u001b[0m ), _ \u001b[38;5;129;01min\u001b[39;00m grouped_tensors\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    494\u001b[0m     device_params \u001b[38;5;241m=\u001b[39m cast(List[Tensor], device_params_)\n",
      "File \u001b[0;32m~/Python/FAN-MicroDoppler/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:516\u001b[0m, in \u001b[0;36mOptimizer._group_tensors_by_device_and_dtype\u001b[0;34m(tensorlistlist, with_indices)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m): (tensorlistlist, \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(tensorlistlist[\u001b[38;5;241m0\u001b[39m]))))}\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_group_tensors_by_device_and_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensorlistlist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Python/FAN-MicroDoppler/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Python/FAN-MicroDoppler/.venv/lib/python3.12/site-packages/torch/utils/_foreach_utils.py:37\u001b[0m, in \u001b[0;36m_group_tensors_by_device_and_dtype\u001b[0;34m(tensorlistlist, with_indices)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;129m@no_grad\u001b[39m()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_group_tensors_by_device_and_dtype\u001b[39m(\n\u001b[1;32m     34\u001b[0m     tensorlistlist: TensorListList,\n\u001b[1;32m     35\u001b[0m     with_indices: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     36\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[Tuple[torch\u001b[38;5;241m.\u001b[39mdevice, torch\u001b[38;5;241m.\u001b[39mdtype], Tuple[TensorListList, Indices]]:\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_group_tensors_by_device_and_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensorlistlist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "##########################################\n",
    "# 4) MAIN PIPELINE\n",
    "##########################################\n",
    "def main():\n",
    "    # A) Load\n",
    "    train, test, sub = load_data()\n",
    "    train['date'] = pd.to_datetime(train['date'])\n",
    "    test['date']  = pd.to_datetime(test['date'])\n",
    "\n",
    "    # B) Preprocess\n",
    "    # fill missing in train\n",
    "    train = fill_missing_mean(train)\n",
    "\n",
    "    # C) Apply \"Kaggle transform\" to train's num_sold\n",
    "    train, transform_stats = kaggle_transform_num_sold(train)\n",
    "\n",
    "    # D) We'll keep date, country, store, product, but numeric for grouping & sliding windows\n",
    "    # Sort train by (country, store, product, date)\n",
    "    train = train.sort_values(['country','store','product','date'])\n",
    "\n",
    "    # E) Build multi-series dataset with sliding windows\n",
    "    seq_len = 96\n",
    "    train_ds = MultiSeriesDataset(train, seq_len=seq_len)\n",
    "    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "\n",
    "    # F) Initialize model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = FANTimeSeries(seq_len=seq_len, d_model=64, e_layers=2, d_layers=1).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=3)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # G) Train loop\n",
    "    epochs = 50\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        print(f\"Allocated Memory: {torch.cuda.memory_allocated(device) / 1024 ** 2:.2f} MB\")\n",
    "        print(f\"Cached Memory: {torch.cuda.memory_reserved(device) / 1024 ** 2:.2f} MB\")\n",
    "        for x_seq, y_val in train_loader:\n",
    "            x_seq, y_val = x_seq.to(device), y_val.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(x_seq)  # shape [B]\n",
    "            loss = criterion(pred, y_val)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * len(x_seq)\n",
    "        total_loss /= len(train_ds)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, train_loss={total_loss:.4f}\")\n",
    "        scheduler.step(total_loss)\n",
    "    # H) Save model\n",
    "    torch.save(model.state_dict(), \"fan_model_timeseries.pth\")\n",
    "    print(\"Model saved.\")\n",
    "\n",
    "    # I) Build a dictionary of historical data for each group, including the train portion\n",
    "    # for easy inference\n",
    "    # We'll store *transformed* num_sold in a structure so we can keep rolling forward\n",
    "    history = {}\n",
    "    for (c,s,p), gdf in train.groupby([\"country\",\"store\",\"product\"]):\n",
    "        gdf = gdf.sort_values(\"date\")\n",
    "        history[(c,s,p)] = list(gdf['num_sold'].values)  # store as a list of transformed values\n",
    "\n",
    "    # J) Inference on test\n",
    "    # We'll sort test by date and do a rolling approach: for each row => build the last 96 from that group\n",
    "    test = test.sort_values([\"country\",\"store\",\"product\",\"date\"])\n",
    "\n",
    "    predictions = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, row in test.iterrows():\n",
    "            c = row['country']\n",
    "            s = row['store']\n",
    "            p = row['product']\n",
    "            # retrieve that group's history\n",
    "            if (c,s,p) not in history:\n",
    "                history[(c,s,p)] = []  # if group not in train, start empty\n",
    "\n",
    "            group_hist = history[(c,s,p)]\n",
    "\n",
    "            # Build input x_seq\n",
    "            if len(group_hist) < seq_len:\n",
    "                # pad with zeros if not enough history\n",
    "                padded = [0.0]*(seq_len - len(group_hist)) + group_hist\n",
    "                x_seq = np.array(padded[-seq_len:], dtype=np.float32)\n",
    "            else:\n",
    "                x_seq = np.array(group_hist[-seq_len:], dtype=np.float32)\n",
    "\n",
    "            x_seq_ten = torch.tensor([x_seq], device=device)  # shape [1, seq_len]\n",
    "            pred_t = model(x_seq_ten)  # shape [1]\n",
    "            pred_val = pred_t.item()   # transformed\n",
    "            # store it into group_hist for future windows\n",
    "            group_hist.append(pred_val)\n",
    "\n",
    "            # invert\n",
    "            num_sold_pred = invert_kaggle_transform(np.array([pred_val], dtype=np.float32), transform_stats)[0]\n",
    "            predictions.append(num_sold_pred)\n",
    "\n",
    "    # K) Build submission\n",
    "    submission = pd.DataFrame({\n",
    "        'id': test['id'],\n",
    "        'num_sold': predictions\n",
    "    })\n",
    "    submission.to_csv(\"submission.csv\", index=False)\n",
    "    print(\"submission.csv created!\")\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10652996,
     "sourceId": 85723,
     "sourceType": "competition"
    },
    {
     "datasetId": 6501797,
     "sourceId": 10501562,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6501798,
     "sourceId": 10501567,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
